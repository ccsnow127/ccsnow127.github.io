---
layout: post
title: Monte Carlo Tree Search (MCTS)
date: 2025-03-30
description: I like to learn by asking questions and answering them. Here are some great QAs about MCTS.
tags: study-with-me
categories: MCTS 
thumbnail: assets/img/mcts/mcts1.png
featured: true
images:
  compare: true
  slider: true
toc:
  beginning: true
---

<div class="row justify-content-sm-center">
 <div class="col-sm-8 mt-3 mt-md-0">
    {% include figure.liquid loading="eager" path="assets/img/mcts/mcts1.png" class="img-fluid rounded z-depth-1" zoomable=true %}
  </div>
</div>

# What is the "tree" in MCTS?

The “tree” is a search structure in which each node corresponds to a specific state of the game (or decision problem), and each edge (link between nodes) corresponds to an action leading from one state to another. The root node represents the current (initial) state; from there, each child node represents a possible next state obtained by applying one of the available actions. As MCTS proceeds, it selectively expands and refines different branches of this tree based on simulated outcomes, storing statistics (like average payoffs and visit counts) in the nodes. Over many iterations, promising actions get explored more thoroughly, so the resulting tree becomes a focused map of the most relevant state–action sequences for the decision at hand.

# How to find the child nodes of the current node in MCTS?

child nodes are determined by generating the states reachable from the current node (i.e., from the current state) via all valid actions.

# How to select the child node in MCTS?

In Monte Carlo Tree Search, child-node selection is generally guided by a tree policy that balances exploration and exploitation.
* **Exploration** encourages the search to explore less-visited parts of the tree, which may contain promising actions that have not yet been thoroughly evaluated.
* **Exploitation** encourages the search to focus on actions that have shown promise in the past, based on the statistics stored in the tree nodes.

## UCT (Upper Confidence Bound for Trees)

1. Expand (or sample) any unvisited child first, if available.
2. If all children have been visited, choose the child maximizing the UCT score.  
$$
UCT(s,c) = Q(s,c) + C \times \sqrt{\frac{\log N(s)}{N(s,c)}}
$$  
where:
* $$s$$ is the parent node,
* $$c$$ is the child node,
* $$Q(s,c)$$ is the average payoff of the child node,
* $$N(s)$$ is the visit count of the parent node,
* $$N(s,c)$$ is the visit count of the child node, and
* $$C$$ is a constant that controls the balance between exploration and exploitation. 

# How many child nodes should be selected in MCTS?
