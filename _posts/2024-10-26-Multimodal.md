---
layout: post
title: 
date: 2024-10-26
description: 
tags: multimodal
categories: tutorial
thumbnail: 
featured: true
images:
  compare: true
  slider: true
toc:
  beginning: true
---

# Resources: [Multimodal RAG: Chat with Videos](https://learn.deeplearning.ai/courses/multimodal-rag-chat-with-videos)

* You can check out the code for [Multimodal Embeddings](/projects/Multimodal-Embeddings/), [Multimodal Preprocessing](/projects/1-Multimodal-Preprocessing/), [Multimodal Retrieval from Vector Stores](/projects/2-Multimodal-Retrieval/), and [Large Vision-Language Models (LVLMs)](/projects/3-LVLM/).

<div class="row justify-content-sm-center">
 <div class="col-sm-8 mt-3 mt-md-0">
    {% include figure.liquid loading="eager" path="assets/img/Multimodal/arc-lmm-rag.png" class="img-fluid rounded z-depth-1" zoomable=true %}
  </div>
</div>

## Cross-Modal Encoder: Bridge Tower

<div class="row justify-content-sm-center">
  <div class="col-sm-8 mt-3 mt-md-0">
    {% include figure.liquid loading="eager" path="assets/img/Multimodal/Bridge-Tower.png" class="img-fluid rounded z-depth-1" zoomable=true %}
  </div>
</div>

## LVLM

<div class="row justify-content-sm-center">
  <div class="col-sm-6 mt-3 mt-md-0">
    {% include figure.liquid loading="eager" path="assets/img/Multimodal/LLM-vs-LVLM.png" class="img-fluid rounded z-depth-1" zoomable=true %}
  </div>
</div>

# Resources: [LMM prompting with Gemini](https://learn.deeplearning.ai/courses/large-multimodal-model-prompting-with-gemini)

